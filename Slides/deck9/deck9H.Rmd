---
title: "Sta112FS <br> 9. Multiple regression, interaction effects, and model selection"
author: "Dr. Ã‡etinkaya-Rundel"
date: "September 24, 2015"
output:
  html_document:
    highlight: pygments
    css: ../lec.css
---

```{r set-options, echo=FALSE, cache=FALSE}
options(width = 90)
```

# Today's agenda

## Today's agenda

- Review App Ex from last time
    - Recap modeling with logged response variable

- Multiple linear regression
    - So you can explain more of the variability in the response variable
    
- Interaction variables
    - So you can start building models that better reflect reality
    
- Model selection
    - So you can decide on the best model(s)

- **Due Tuesday:** 
    - App Ex 5: Requires consultation with Sandra


# Initial setup

## Load packages & data + data fixes

Load packages:
```{r message=FALSE}
library(ggplot2)
library(dplyr)
library(stringr)
```

Load data:
```{r echo=FALSE}
pp <- read.csv("../../Data/paris_paintings.csv", stringsAsFactors = FALSE) %>%
  tbl_df()
```

```{r eval=FALSE}
pp <- read.csv("paris_paintings.csv", stringsAsFactors = FALSE) %>%
  tbl_df()
```

Fix prices:
```{r}
pp <- pp %>%
  mutate(price = as.numeric(str_replace(price, ",", "")))
```

## More data fixes {.smaller}

Fix shape coding:
```{r}
pp <- pp %>%
  mutate(shape_recode = ifelse(Shape == "", NA,
                               ifelse(Shape == "ovale", "oval",
                                      ifelse(Shape == "ronde", "round",
                                             ifelse(Shape == "octogon", "octagon", Shape)))))
```

Fix material coding:
```{r}
pp <- pp %>%
  mutate(mat_recode = ifelse(mat %in% c("a", "bc", "c"), "metal",
                             ifelse(mat %in% c("al", "ar", "m"), "stone",
                                    ifelse(mat %in% c("co", "bt", "t"), "canvas",
                                           ifelse(mat %in% c("p", "ca"), "paper",
                                                  ifelse(mat %in% c("b"), "wood",
                                                         ifelse(mat %in% c("o", "e", "v"), "other",
                                                                ifelse(mat %in% c("n/a", ""), NA,
                                                                       "uncertain"))))))))
```
# Multiple linear regression

## From last time...

The linear model with multiple predictors

- Population model:
\[ \hat{y} = \beta_0 + \beta_1~x_1 + \beta_2~x_2 + \cdots + \beta_k~x_k \]

- Sample model that we use to estimate the population model:
\[ \hat{y} = b_0 + b_1~x_1 + b_2~x_2 + \cdots + b_k~x_k \]

# Main effects

## Price, surface, and living artist {.smaller}

Very few paintings withs `Surface >= 5000`:

```{r fig.height=4, echo=FALSE,warning=FALSE}
ggplot(data = pp, aes(y = log(price), x = Surface, color = factor(artistliving))) +
  geom_point(alpha = 0.3)
```

## Price, surface, and living artist {.smaller}

For simplicity let's focus on the paintings with `Surface < 5000`:

```{r fig.height=4, echo=FALSE,warning=FALSE}
pp_Surf_lt_5000 <- pp %>%
  filter(Surface < 5000)

ggplot(data = pp_Surf_lt_5000, 
       aes(y = log(price), x = Surface, color = factor(artistliving))) +
  geom_point(alpha = 0.3)
```

## Price vs. surface and living artist {.smaller}

<div class="question">
Does the relationship between surface and logged price vary by whether or not
the artist is living?
</div>

```{r fig.height=3.5}
ggplot(data = pp_Surf_lt_5000,
       aes(y = log(price), x = Surface, color = factor(artistliving))) +
  geom_point(alpha = 0.3) +
  stat_smooth(method = "lm", fullrange = TRUE)
```

## Modeling with main effects 

```{r}
(m_main <- lm(log(price) ~ Surface + factor(artistliving), data = pp_Surf_lt_5000))
```

\[\widehat{log(price)} = 4.88 + 0.00027~surface + 1.14~artistliving \]

- Plug in 0 for `artistliving` to get the linear model for paintings by non-living
artists.

- Plug in 1 for `artistliving` to get the linear model for paintings by living
artists.

## Interpretation of main effects {.smaller}

<div class="columns-2">

```{r fig.height=3.5, echo = FALSE}
ggplot(data = pp_Surf_lt_5000,
       aes(y = log(price), x = Surface, color = factor(artistliving))) +
  geom_point(alpha = 0.3) +
  geom_abline(intercept = 4.88, slope = 0.00027, color = "#F57670", lwd = 1) +
  geom_abline(intercept = 6.02, slope = 0.00027, color = "#1FBEC3", lwd = 1)
```

- Non-living artist: 
$\widehat{log(price)} = 4.88 + 0.00027~surface + 1.14 \times 0$
$= 4.88 + 0.00027~surface$

- Living artist: 
$\widehat{log(price)} = 4.88 + 0.00027~surface + 1.14 \times 1$
$= 6.02 + 0.00027~surface$
</div>

- Rate of change in price as the surface area of the painting increases does 
not vary between paintings by living and non-living artists (same slope), 

- Paintings by living artists are consistently more expensive than paintings by
non-living artists (different intercept).

# Interaction effects

## Interacting explanatory variables

- Including an interaction effect in the model allows for different slopes, i.e. 
nonparallel lines.

- This implies that the regression coefficient for an explanatory variable would 
change as another explanatory variable changes.

- This can be accomplished by adding an interaction variable: the product of two 
explanatory variables.

## Price vs. surface and artist living interacting {.smaller}

```{r fig.height=3.5}
ggplot(data = pp_Surf_lt_5000,
       aes(y = log(price), x = Surface, color = factor(artistliving))) +
  geom_point(alpha = 0.3) +
  stat_smooth(method = "lm", fullrange = TRUE)
```

## Modeling with interaction effects {.smaller}

```{r}
(m_int <- lm(log(price) ~ Surface * factor(artistliving), data = pp_Surf_lt_5000))
```

\[\widehat{log(price)} = 4.91 + 0.00021~surface - 0.126~artistliving + 0.00048~surface \times artistliving \]

## Interpretation of interaction effects {.smaller}

<div class="columns-2">

```{r fig.height=3.5, echo = FALSE}
ggplot(data = pp_Surf_lt_5000,
       aes(y = log(price), x = Surface, color = factor(artistliving))) +
  geom_point(alpha = 0.3) +
  stat_smooth(method = "lm", fullrange = TRUE)
```

- Non-living artist: 
$\widehat{log(price)} = 4.91 + 0.00021~surface$
$- 0.126 \times 0 + 0.00048~surface \times 0$
$= 4.91 + 0.00021~surface$

- Living artist: 
$\widehat{log(price)} = 4.91 + 0.00021~surface$
$- 0.126 \times 1 + 0.00048~surface \times 1$
$= 4.91 + 0.00021~surface$
$- 0.126 + 0.00048~surface$
$= 4.784 + 0.00069~surface$
</div>

- Rate of change in price as the surface area of the painting increases does 
vary between paintings by living and non-living artists (different slopes), 

- Paintings by living artists are consistently more expensive than paintings by
non-living artists (different intercept).

## Third order interactions

- Can you? Yes

- Should you? Probably not if you want to interpret these interactions in context
of the data.


# Quality of fit in MLR

## $R^2$ {.smaller .build}

>- $R^2$ is the percentage of variability in the response variable explained by the 
regression model.

```{r}
summary(m_main)$r.squared
summary(m_int)$r.squared
```

>- Clearly the model with interactions has a higher $R^2$.

>- However using $R^2$ for model selection in models with multiple explanatory 
variables is not a good idea as $R^2$ increases when **any** variable is added to the 
model.

## $R^2$ - first principles {.smaller}

\[ R^2 =  \frac{ SS_{Reg} }{ SS_{Total} } = 1 - \left( \frac{ SS_{Error} }{ SS_{Total} } \right) \]

```{r}
anova(m_main)
```

\[ R^2_{m\_main} = \frac{138.5 + 6.8}{138.5 + 6.8 + 10858.4} = \frac{145.3}{11003.7} \approx 0.013 \]

## $R^2$ - first principles {.smaller}

\[ R^2 =  \frac{ SS_{Reg} }{ SS_{Total} } = 1 - \left( \frac{ SS_{Error} }{ SS_{Total} } \right) \]

```{r}
anova(m_int)
```

\[ R^2_{m\_int} = \frac{138.5 + 6.8 + 49.3}{138.5 + 6.8 + 49.3 + 10809.1} = \frac{194.6}{11003.7} \approx 0.018 \]


## Adjusted $R^2$ {.build}

\[ R^2_{adj} = 1 - \left( \frac{ SS_{Error} }{ SS_{Total} } \times \frac{n - 1}{n - k - 1} \right) \]
where $n$ is the number of cases and $k$ is the number of predictors in the model

>- Adjusted $R^2$ doesn't increase if the new variable does not provide any new 
informaton or is completely unrelated.

>- This makes adjusted $R^2$ a preferable metric for model selection in multiple
regression models.

## In pursuit of Occam's Razor

- Occam's Razor states that among competing hypotheses that predict equally well, 
the one with the fewest assumptions should be selected.

- Model selection follows this principle.

- We only want to add another variable to the model if the addition of that
variable brings something valuable in terms of predictive power to the model.

- In other words, we prefer the simplest best model, i.e. **parsimonious** model.

## Comparing models

It appears that adding the interaction actually increased adjusted $R^2$, so we 
should indeed use the model with the interactions.

```{r}
summary(m_main)$adj.r.squared
summary(m_int)$adj.r.squared
```


# Model selection methods

## Backwards elimination {.build}

>- Start with **full** model (including all candidate explanatory variables and all
candidate interactions)

>- Remove one variable at a time, and select the model with the highest adjusted $R^2$

>- Continue until adjusted $R^2$ does not increase


## Forward selection {.build}

>- Start with **empty** model

>- Add one variable (or interaction effect) at a time, and select the model with the 
highest adjusted $R^2$

>- Continue until adjusted $R^2$ does not increase


## Model selection and interaction effects

If an interaction is included in the model, the main effects of both of
those variables must also be in the model


## Other model selection criteria

- Adjusted $R^2$ is one model selection criterion

- There are others out there (many many others!), we'll discuss some later in the 
course, and some you might see in another course


# Application Exercise

## App Ex 5

See course website.